---
title: "Distance Sampling"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Distance Sampling Lab

## Set-Up

As always, we need to load the packages we will need to complete this lab, which are `tidyverse` and `unmarked`.

```{r message = FALSE}
library(tidyverse)
library(unmarked) # Load unmarked
```

We also need to load our data. I've compiled it for you already, and it should be in your list of files, called `Distance_Data.csv`.

There is some *wonky* stuff that goes on in `unmarked` if we use our usual `read_csv()` function, so be sure to use `read.csv()` this time!

```{r}
beads <- read.csv("Distance_Data.csv")
```

Before we begin any analyses, let's make sure our data looks alright.

```{r}
str(beads)    # View the structure of the dataframe
head(beads)   # First few observations
```

## Prepping the Data

First, we need to convert all of our data from inches into meters because those are the measurements `unmarked` is expecting. You won't need to do this in your assignment, thankfully, because those values are already in meters.

```{r}
beads <- beads %>% 
  mutate(TransectLength_m = TransectLength_ft / 3.281,
         Distance_m = Distance_in / 39.37)
```

Since we have 2 different colors of beads, we need to create two different data frames. You won't need to do this in your assignment, thankfully!

```{r}
clear <- beads %>% 
  filter(BeadColor == "Clear")
green <- beads %>% 
  filter(BeadColor == "Green")
```

Take a look at the environment to see how many rows the `clear` and `green` data frames have. The `green` data frame has nearly double the observations as the `clear`. Is that expected? Why or why not?

## Green Beads

### Transect Data

The first thing we need to do is to get a data frame that includes the length of transect that each group walked so we have a measure of survey effort.

Simply based on how the data is structured (survey length column, so every value has the same survey length), the easiest way to get the survey length is by taking the mean or median of the length for each group.

```{r}
transect_length <- green %>% 
  group_by(GroupID) %>% 
  summarise(length = mean(TransectLength_m))
```

Let's check out our distribution of detection distances. We can use the `hist()` function to do this.

```{r}
hist(green$Distance_m)
```

Based on the histogram, I'll suggest we truncate at 2.5 m. Let's set this value so we can refer to it later.

```{r}
# Set truncation distance to eliminate extreme observations
trunc <- 2.5
```

We can set "cut points" for distance bins; in our case, we want every 1 meter.

This line of code creates a vector that will have values every half meter (`by = 0.5`), starting at 0 and running through the value we set for truncation (`trunc`).

```{r}
distance_bins <- seq(0, trunc, by = 0.5) 
```

## `unmarked` Data Prep

As we've seen before, the `unmarked` package likes to have data set up in a very specific way and has specific functions for this.

To get our detection functions and density estimates, we will use the `formatDistData` to get the data into the correct format.

```{r}
green_data <- formatDistData(distData = green,         # data frame
                        distCol = "Distance_m",        # column that holds the distance values
                        transectNameCol = "GroupID",   # column that holds the transect groups 
                        dist.breaks = distance_bins)   # vector of distance groupings
green_data
```

*P.S. - If you're having issues in the code chunk above (along the lines of "The distances must be numeric", you probably used the `read_csv()` function (with an underscore) instead of `read.csv()`. There is something very odd that happens when we use `read_csv()` that doesn't play nicely with `unmarked`, but I haven't been able to track it down. Head back to where we read in that data and change the function. Run that code chunk, and you should be good to go.*

Next, we need to assemble data into the format required by `unmarked`, called an "unmarked frame". We've seen something similar before, but this one is `unmarkedFrameDS`, with the DS meaning "distance sampling."

```{r}
UMF_green <- unmarkedFrameDS(y = as.matrix(green_data), 
                       survey = "line", 
                       tlength = transect_length$length, 
                       dist.breaks = distance_bins, 
                       unitsIn = "m")
UMF_green
```

Let's check the distribution of detection distances to be used for analysis. These should *not* include the values that we truncated.

```{r}
hist(UMF_green) 
```

## Models

Now that our data is in the correct format for `unmarked`, we can use the `distsamp` function from `unmarked` to create our 4 types of models: half normal, hazard rate, uniform, and negative exponential.

Our options for the `unitsOut` argument is either hectares (ha) or kilomenter (km). We will use hectares. This means that the density we calculate will be the density of beads per hectare.

```{r}
HN   <- distsamp(~1 ~1, UMF_green, keyfun = "halfnorm", output = "density", unitsOut = "ha")
HR   <- distsamp(~1 ~1, UMF_green, keyfun = "hazard",output = "density", unitsOut = "ha")
Unif <- distsamp(~1 ~1, UMF_green, keyfun = "uniform",output = "density", unitsOut = "ha")
Exp  <- distsamp(~1 ~1, UMF_green, keyfun = "exp", output = "density", unitsOut = "ha")
```

### Model Selection

Which model should we choose? We will use AIC again to help us figure it out. We want the model with the *lowest* AIC value.

```{r}
models <- fitList('Half Normal' = HN, 
                  'Hazard Rate' = HR,
                  'Uniform'     = Unif,
                  'Exponential' = Exp)
modSel(models)
```

## Density Estimate

Now that we've chosen our top model (half natural, in this case), we can get our density estimate!

There is a handy function that we can use to pull the density estimate out of the model: `backTransform()`

```{r}
backTransform(HN, type = "state") # Density estimate (no./ha) 
```

We can also calculate the confidence intervals for our parameter estimate

```{r}
exp(confint(HN, type = "state"))  # CI for density
```

### Convert to Our Sample Area

You won't need to do this in your assignment---we will just leave all of our density estimates in the numbers per hectare. For our bead data, however, we definitely didn't sample a whole hectare (100m x 100m).

To see how close our estimate was to the actual number of beads we put outside (\#), we need to convert the density in hectares to the density of our survey area.

```{r}
# Current density estimate:
# D-hat = 3231 / ha

# Our survey area = 12 x 45 m 
area <- 12 * 40 # 540 m^2

# One hectare = 100 m x 100 m
ha <- 100 * 100 # 10,000 m^2

# Calculate the density of beads for the entirety of our sample area (same as abundance!)
# D-hat * area/ha
3231 * area/ha
```

Katherine and I put out 150 green beads, so this is actually quite accurate!

## Clear Beads

Just out of curiosity...what happens when we use the data from the clear beads?

```{r}
transect_length <- clear %>% 
  group_by(GroupID) %>% 
  summarise(length = mean(TransectLength_m))

hist(clear$Distance_m) # keep distance bins the same

clear_data <- formatDistData(distData = clear,         # data frame
                        distCol = "Distance_m",        # column that holds the distance values
                        transectNameCol = "GroupID",   # column that holds the transect groups 
                        dist.breaks = distance_bins)   # vector of distance groupings

UMF_clear <- unmarkedFrameDS(y = as.matrix(clear_data), 
                       survey = "line", 
                       tlength = transect_length$length, 
                       dist.breaks = distance_bins, 
                       unitsIn = "m")

HNc   <- distsamp(~1 ~1, UMF_clear, keyfun = "halfnorm", output = "density", unitsOut = "ha")
HRc   <- distsamp(~1 ~1, UMF_clear, keyfun = "hazard",output = "density", unitsOut = "ha")
Unifc <- distsamp(~1 ~1, UMF_clear, keyfun = "uniform",output = "density", unitsOut = "ha")
Expc  <- distsamp(~1 ~1, UMF_clear, keyfun = "exp", output = "density", unitsOut = "ha")

models <- fitList('Half Normal' = HNc, 
                  'Hazard Rate' = HRc,
                  'Uniform'     = Unifc,
                  'Exponential' = Expc)
modSel(models)

# Half-Normal model again
backTransform(HNc, type = "state")  # 1527
exp(confint(HNc, type = "state"))

# Abundance Estimate
# D-hat * area/ha
1527 * area/ha # <- actual value was 150
```
