---
title: "Distance Sampling"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Distance Sampling Lab

## Set-Up

We need to load the package we will need to complete this lab, which is `unmarked`.

```{r message = FALSE}
library(unmarked) # Load unmarked
```

We also need to load our data. I've compiled it for you already, and it should be in your list of files, called `Distance_Data_Spring2024.csv`.

```{r}
beads <- read.csv("../data_raw/Distance_Data_Fall2024.csv")
```

Before we begin any analyses, let's make sure our data looks alright.

```{r}
str(beads)    # View the structure of the dataframe
head(beads)   # First few observations
```

## Prepping the Data

First, we need to convert all of our data from inches into meters because those are the measurements `unmarked` is expecting. You won't need to do this in your assignment, thankfully, because those values are already in meters.

```{r}
beads$Distance_m <- beads$Distance_in / 39.37
```

Since we have 2 different colors of beads, we need to create two different data frames. You won't need to do this in your assignment, either, thankfully!

```{r}
clear <- beads[beads$BeadColor == "Clear", ] 
green <- beads[beads$BeadColor == "Green", ]
```

Take a look at the environment to see how many rows the `clear` and `green` data frames have. The `green` data frame has more observations than the `clear`. Is that expected? Why or why not?

## Green Beads

### Transect Data

The first thing we need to do is to get a data frame that includes the length of transect that each group walked so we have a measure of survey effort.

Simply based on how the data is structured (survey length column, so every value has the same survey length), the easiest way to get the survey length is by taking the mean or median of the length for each group.

```{r}
# create a data frame that has a column for each group id and a column for the length that each group surveyed. in our case, the length is the same.
transect_length <- data.frame(group_id = 1:10,
                              length_m = 37)
transect_length
```

Let's check out our distribution of detection distances. We can use the `hist()` function to do this.

```{r}
hist(green$Distance_m)
```

Based on the histogram, I'll suggest we truncate at 2.5 m. Let's set this value so we can refer to it later.

```{r}
# Set truncation distance to eliminate extreme observations
trunc <- 3
```

We can set "cut points" for distance bins; in our case, we want every half meter.

This line of code creates a vector that will have values every half meter (`by = 0.5`), starting at 0 and running through the value we set for truncation (`trunc`).

```{r}
distance_bins <- seq(0, trunc, by = 0.25) 
```

## `unmarked` Data Prep

As we've seen before, the `unmarked` package likes to have data set up in a very specific way and has specific functions for this.

To get our detection functions and density estimates, we will use the `formatDistData` to get the data into the correct format.

```{r}
# create an unmarked data frame
green_data <- formatDistData(distData = green,         # data frame with the data points
                        distCol = "Distance_m",        # column that holds the distance values
                        transectNameCol = "GroupID",     # column that holds the transect groups
                        dist.breaks = distance_bins)   # vector of distance groupings
green_data
```

Next, we need to assemble data into the format required by `unmarked`, called an "unmarked frame". We've seen something similar before, but this one is `unmarkedFrameDS`, with the DS meaning "distance sampling."

```{r}
UMF_green <- unmarkedFrameDS(y = as.matrix(green_data), 
                       survey = "line", 
                       tlength = transect_length$length_m, 
                       dist.breaks = distance_bins, 
                       unitsIn = "m")
UMF_green
```

Let's check the distribution of detection distances to be used for analysis. These should *not* include the values that we truncated.

```{r}
hist(UMF_green) 
```

## Models

Now that our data is in the correct format for `unmarked`, we can use the `distsamp` function from `unmarked` to create our 4 types of models: half normal, hazard rate, uniform, and negative exponential.

Our options for the `unitsOut` argument is either hectares (ha) or kilomenter (km). We will use hectares. This means that the density we calculate will be the density of beads per hectare.

```{r}
HN   <- distsamp(~1 ~1, UMF_green, keyfun = "halfnorm", output = "density", unitsOut = "ha")
HR   <- distsamp(~1 ~1, UMF_green, keyfun = "hazard",output = "density", unitsOut = "ha")
Unif <- distsamp(~1 ~1, UMF_green, keyfun = "uniform",output = "density", unitsOut = "ha")
Exp  <- distsamp(~1 ~1, UMF_green, keyfun = "exp", output = "density", unitsOut = "ha")
```

### Model Selection

Which model should we choose? We will use AIC again to help us figure it out. We want the model with the *lowest* AIC value.

```{r}
models <- fitList('Half Normal' = HN, 
                  'Hazard Rate' = HR,
                  'Uniform'     = Unif,
                  'Exponential' = Exp)
modSel(models)
```

Let's plot what the half-normal model looks like with our data.

```{r}
hist(HN)
```

## Density Estimate

Now that we've chosen our top model (half normal, in this case), we can get our density estimate!

There is a handy function that we can use to pull the density estimate out of the model: `backTransform()`

```{r}
density <- backTransform(HN, type = "state") # Density estimate (no./ha) 
density
```

We can also calculate the confidence intervals for our parameter estimate

```{r}
exp(confint(HN, type = "state"))  # CI for density
```

### Convert to Our Sample Area

You won't need to do this in your assignment---we will just leave all of our density estimates in the numbers per hectare. For our bead data, however, we definitely didn't sample a whole hectare (100m x 100m).

To see how close our estimate was to the actual number of beads we put outside (\#), we need to convert the density in hectares to the density of our survey area.

```{r}
# Current density estimate:
density_est <- density@estimate

# Half Normal SD
sigma <- backTransform(HN, type = "det")@estimate

# Effective Strip Width
esw <- integrate(gxhn, 0, 2, sigma = sigma)$value
esw

# Our survey area = 10 groups x (2*esw*L) 
area <- 10 * (2 * esw * 32) # 480 m^2

# One hectare = 100 m x 100 m
ha <- 100 * 100 # 10,000 m^2

# Calculate the density of beads for the entirety of our sample area (same as abundance!)
# D-hat * area/ha
density_est * area/ha
```

I put out 150 green beads, so this is pretty good!

## Clear Beads

Just out of curiosity...what happens when we use the data from the clear beads?

```{r}
hist(clear$Distance_m) # keep distance bins the same

clear_data <- formatDistData(distData = clear,         # data frame
                        distCol = "Distance_m",        # column that holds the distance values
                        transectNameCol = "GroupID",   # column that holds the transect groups
                        dist.breaks = distance_bins)   # vector of distance groupings

UMF_clear <- unmarkedFrameDS(y = as.matrix(clear_data),
                       survey = "line",
                       tlength = transect_length$length,
                       dist.breaks = distance_bins,
                       unitsIn = "m")

HNc   <- distsamp(~1 ~1, UMF_clear, keyfun = "halfnorm", output = "density", unitsOut = "ha")
hist(HNc)

# Exponential model
d_hat <- backTransform(HNc, type = "state")@estimate  
d_hat

exp(confint(HNc, type = "state"))

# Abundance Estimate
# D-hat * area/ha
d_hat * area/ha # <- actual value was 150
```
