---
title: "Distance Sampling"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Distance Sampling Lab

## Set-Up

As always, we need to load the packages we will need to complete this lab, which are `tidyverse` and `unmarked`.

```{r}
library(tidyverse)
library(unmarked) # Load unmarked
```

We also need to load our data. I've compiled it for you already, and it should be in your list of files, called `bead_data_2022.csv` or something along those lines.

There is some *wonky* stuff that goes on in `unmarked` if we use our usual `read_csv()` function, so be sure to use `read.csv()` this time!

```{r}
beads <- read.csv("data_raw/bead_data_2021.csv")
```

Before we begin any analyses, let's make sure our data looks alright.

```{r}
str(beads)    # View the structure of the dataframe
head(beads)   # First few observations
```

## Prepping the Data

The first thing we need to do is to get a data frame that includes the length of transect that each group walked so we have a measure of survey effort.

Simply based on how the data is structured (survey length column, so every value has the same survey length), the easiest way to get the survey length is by taking the mean or median of the length for each group.

```{r}
transect_length <- beads %>% 
  group_by(group) %>% 
  summarise(length = mean(length))
```

Let's check out our distribution of detection distances. We can use the `hist()` function to do this.

```{r}
hist(beads$distance)
```

Based on the histogram, I'll suggest we truncate at 5 m. Let's set this value so we can refer to it later.

```{r}
# Set truncation distance to eliminate extreme observations
trunc <- 5
```

We can set "cut points" for distance bins; in our case, we want every 1 meter.

This line of code creates a vector that will have values every 1 meter (`by = 1`), starting at 0 and running through the value we set for truncation (`trunc`).

```{r}
distance_bins <- seq(0, trunc, by = 1) 
```

## `unmarked` Data Prep

As we've seen before, the `unmarked` package likes to have data set up in a very specific way and has specific functions for this.

To get our detection functions and density estimates, we will use the `formatDistData` to get the data into the correct format.

```{r}
data <- formatDistData(distData = beads,              # data frame
                       distCol = "distance",          # column that holds the distance values
                       transectNameCol = "group",     # column that holds the transect groups 
                       dist.breaks = distance_bins)   # vector of distance groupings
data
```

*P.S. - If you're having issues in the code chunk above (along the lines of "The distances must be numeric", you probably used the `read_csv()` function (with an underscore) instead of `read.csv()`. There is something very odd that happens when we use `read_csv()` that doesn't play nicely with `unmarked`, but I haven't been able to track it down. Head back to where we read in that data and change the function. Run that code chunk, and you should be good to go.*

Next, we need to assemble data into the format required by `unmarked`, called an "unmarked frame". We've seen something similar before, but this one is `unmarkedFrameDS`, with the DS meaning "distance sampling."

```{r}
UMF <- unmarkedFrameDS(y = as.matrix(data), 
                       survey = "line", 
                       tlength = transect_length$length, 
                       dist.breaks = distance_bins, 
                       unitsIn = "m")
UMF
```

Let's check the distribution of detection distances to be used for analysis. These should *not* include the values that we truncated.

```{r}
hist(UMF) 
```

## Models

Now that our data is in the correct format for `unmarked`, we can use the `distsamp` function from `unmarked` to create our 4 types of models: half normal, hazard rate, uniform, and negative exponential.

Our options for the `unitsOut` argument is either hectares (ha) or kilomenter (km). We will use hectares. This means that the density we calculate will be the density of beads per hectare.

```{r}
HN   <- distsamp(~1 ~1, UMF, keyfun = "halfnorm", 
                 output = "density", unitsOut = "ha")
HR   <- distsamp(~1 ~1, UMF, keyfun = "hazard",
                 output = "density", unitsOut = "ha")
Unif <- distsamp(~1 ~1, UMF, keyfun = "uniform",
                 output = "density", unitsOut = "ha")
Exp  <- distsamp(~1 ~1, UMF, keyfun = "exp", 
                 output = "density", unitsOut = "ha")
```

### Model Selection

Which model should we choose? We will use AIC again to help us figure it out. We want the model with the *lowest* AIC value.

```{r}
models <- fitList('Half Normal' = HN, 
                  'Hazard Rate' = HR,
                  'Uniform'     = Unif,
                  'Exponential' = Exp)
modSel(models)
```

### Demonstration

Below is an illustration of the the distance data with the Hazard rate function. There is *no need for you to repeat this or understand the code*, but I wanted to give you a quick visualization!

```{r}
hr.shape <- exp(coef(HR, type="det"))
hr.scale <- exp(coef(HR, type="scale"))
hist(UMF, xlab = "distance (m)", main = "Beads", cex.lab = 0.8, cex.axis = 0.8) 
par(new = TRUE)
plot(function(x) gxhaz(x, shape = hr.shape, scale = hr.scale), 0, trunc, xaxt='n', yaxt='n', 
     ann = FALSE, col = "blue", lwd = 2)
```

## Density Estimate

Now that we've chosen our top model (half natural, in this case), we can get our density estimate!

There is a handy function that we can use to pull the density estimate out of the model: `backTransform()`

```{r}
backTransform(HN, type = "state") # Density estimate (no./ha) 
```

We can also calculate the confidence intervals for our parameter estimate

```{r}
exp(confint(HN, type = "state"))  # CI for density
```

### Convert to Our Sample Area

You won't need to do this in your assignment---we will just leave all of our density estimates in the numbers per hectare. For our bead data, however, we definitely didn't sample a whole hectare (100m x 100m).

To see how close our estimate was to the actual number of beads we put outside (\#), we need to convert the density in hectares to the density of our survey area.

```{r}
# Current density estimate:
# D-hat = 1528 / ha

# Our urvey area = 12 x 45 m 
area <- 12 * 45 # 540 m^2

# One hectare = 100 m x 100 m
ha <- 100 * 100 # 10,000 m^2

# Calculate the density of beads for the entirety of our sample area (same as abundance!)
# D-hat * area/ha
1528 * area/ha
```
