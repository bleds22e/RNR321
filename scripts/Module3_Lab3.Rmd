---
title: "Distance Sampling"
author: "Ellen Bledsoe"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Distance Sampling Lab

## Set-Up

We need to load the package we will need to complete this lab, which is `unmarked`.

```{r message = FALSE}

```

We also need to load our data. I've compiled it for you already, and it should be in your list of files, called `Distance_Data_Spring2024.csv`.

```{r}

```

Before we begin any analyses, let's make sure our data looks alright.

```{r}

```

## Prepping the Data

First, we need to convert all of our data from inches into meters because those are the measurements `unmarked` is expecting. You won't need to do this in your assignment, thankfully, because those values are already in meters.

```{r}
beads$Distance_m <- beads$Distance_in / 39.37
```

Since we have 2 different colors of beads, we need to create two different data frames. You won't need to do this in your assignment, thankfully!

```{r}
clear <- beads[beads$BeadColor == "Clear", ] 
green <- beads[beads$BeadColor == "Green", ]
```

Take a look at the environment to see how many rows the `clear` and `green` data frames have. Is that expected? Why or why not?

## Green Beads

### Transect Data

The first thing we need to do is to get a data frame that includes the length of transect that each group walked so we have a measure of survey effort.

We will use the `unique()` function, which returns only one of each value in a column. We want the unique values from two of our columns: the group and the transect length. 

```{r}

```

Let's check out our distribution of detection distances. We can use the `hist()` function to do this.

```{r}

```

Based on the histogram, I'll suggest we truncate at 2.5 m. Let's set this value so we can refer to it later.

```{r}
# Set truncation distance to eliminate extreme observations

```

We can set "cut points" for distance bins; in our case, we want every half meter.

This line of code creates a vector that will have values every half meter (`by = 0.5`), starting at 0 and running through the value we set for truncation (`trunc`).

```{r}

```

## `unmarked` Data Prep

As we've seen before, the `unmarked` package likes to have data set up in a very specific way and has specific functions for this.

To get our detection functions and density estimates, we will use the `formatDistData` to get the data into the correct format.

```{r}

```

Next, we need to assemble data into the format required by `unmarked`, called an "unmarked frame". We've seen something similar before, but this one is `unmarkedFrameDS`, with the DS meaning "distance sampling."

```{r}

```

Let's check the distribution of detection distances to be used for analysis. These should *not* include the values that we truncated.

```{r}

```

## Models

Now that our data is in the correct format for `unmarked`, we can use the `distsamp` function from `unmarked` to create our 4 types of models: half normal, hazard rate, uniform, and negative exponential.

Our options for the `unitsOut` argument is either hectares (ha) or kilomenter (km). We will use hectares. This means that the density we calculate will be the density of beads per hectare.

```{r}
# UMF_green is the unmarked data frame for the green beads
HN   <- distsamp(~1 ~1, UMF_green, keyfun = "halfnorm", output = "density", unitsOut = "ha")
HR   <- distsamp(~1 ~1, UMF_green, keyfun = "hazard", output = "density", unitsOut = "ha")
Unif <- distsamp(~1 ~1, UMF_green, keyfun = "uniform", output = "density", unitsOut = "ha")
Exp  <- distsamp(~1 ~1, UMF_green, keyfun = "exp", output = "density", unitsOut = "ha")
```

### Model Selection

Which model should we choose? We will use AIC again to help us figure it out. We want the model with the *lowest* AIC value.

```{r}

```

Let's plot what the half-normal model looks like with our data.

```{r}

```

## Density Estimate

Now that we've chosen our top model (half normal, in this case), we can get our density estimate!

There is a handy function that we can use to pull the density estimate out of the model: `backTransform()`

```{r}

```

We can also calculate the confidence intervals for our parameter estimate

```{r}
# CI for density
```

### Convert to Our Sample Area

You won't need to do this in your assignment---we will just leave all of our density estimates in the numbers per hectare. For our bead data, however, we definitely didn't sample a whole hectare (100m x 100m).

To see how close our estimate was to the actual number of beads we put outside (\#), we need to convert the density in hectares to the density of our survey area.

Our first step is to calculate our effective strip width.

```{r}
# density estimate
density_est <- density@estimate
density_est

# standard deviation
rate <- backTransform(Exp, type = "det")@estimate

# calculate the effective strip width
esw <- integrate(gxexp, 0, 2.5, rate)$value
esw
```

We can then calculate the area surveyed

```{r}
# Our survey area = 10 groups x (2*esw*L) 
area <- 10 * (2 * esw * 10) 
area

# One hectare = 100 m x 100 m
ha <- 100 * 100 # 10,000 m^2
ha

# Proportion of hectare we surveyed
surveyed <- area/ha
surveyed
```

Finally, if we multiple our density estimate by the amount of area we surveyed, we will get the density of beads for the entirety of our sample area (same as abundance!)

```{r}
# D-hat * surveyed
density_est * surveyed
```

I put out 150 green beads, so this is off by a bit! That's ok, though. We did *repeated* surveys in the same area and did not take that into account in our model. If we were going to accurately analyze our data, we would definitely need to do that.

## 
